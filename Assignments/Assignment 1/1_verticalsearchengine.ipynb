{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV-UrkvK3HBQ"
   },
   "source": [
    "# Data-Driven Research Assignment 1: Build your own Vertical Search Engine\n",
    "This notebook contains the first individual graded assignment of the 2023 Data-Driven Research course. In this assignment you will build your own search engine -- and compare against search engine giant Google -- with a realistic chance to do better than Google! \n",
    "\n",
    "To complete the assignment, fill in the **Report part 1**, **Report part 2** and **Report part 3** and **Report part 4**, and complete the **code** in the last section that is needed to write Report part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13WY-Pd4m1Nq"
   },
   "source": [
    "This is an individual assignment. In the text cell below, please add your name.\n",
    "\n",
    "If you used code or a solution from the internet (such as StackOverflow) or another external resource, please make reference to it (in any format). Unattributed copied code will be considered plagiarism and therefore fraud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author of this answer: George Christian Cotea - 13842013**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV4eOyrVqRHQ"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Search engines provide a crucial role in making sense of the almost infinite amount of information online. In fact your mental model of what the web is, is completely determined by the small fraction of web data served in a streamlined way by search engines.  You reliance on search engines also makes them the gatekeeper of information: with millions or billions of search results for every query they determine the ranking with only the first handful of them gets any clicks.   Is this generic approach really optimal for everyone and any topic?\n",
    "\n",
    "A *Vertical Search Engine* is a \"specialized\" search engine that focuses on a specific domain or service, tailored to the\n",
    "particular information needs of niche audiences and professions.  Search experts believe that the performance of general-purpose search engines (such as http://google.com/, http://bing.com/, and http://onesearch.com/ or regional champions like https://baidu.cn/ and https://yandex.ru/) cannot improve much due to the short and highly ambiguous queries that are standard on the web.  A natural alternative to the one-size-fits-all approach of general-purpose search engines is the\n",
    "use of a dedicated vertical search engine, which is expected to provide more focused search results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Accessing Google using Python\n",
    "\n",
    "Probably, you normally access the web by searching for something through a search engine like Google. But what if you want to make use of this information for data-driven or quantitative research purposes? It's kind of a hassle to copy-paste all your search results into a file for further analysis. \n",
    "\n",
    "We could use Python's Request library to simply request a page of search results from Google. Let's try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # External package: https://requests.readthedocs.io/en/master/\n",
    "\n",
    "# Example of a Google search\n",
    "query = \"How to search Google using Python\"\n",
    "headers = {\n",
    "    \"referer\":\"referer: https://www.google.com/\",\n",
    "    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "with requests.Session() as s:\n",
    "    s.post('https://www.google.com/search', params={'q': query}, headers=headers)\n",
    "    r = s.get('https://www.google.com/search', params={'q': query}, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are wondering what the \"headers\" is, it provides information about the user (mainly your browser) to the website. We have to add them here for Google to view us as a regular user and not a first-time user, to avoid getting cookies and privacy consent popups instead of the results that we want.\n",
    "\n",
    "You can find a selection of HTTP headers [here](https://en.wikipedia.org/wiki/List_of_HTTP_header_fields). Here's an explanation for the ones used above:\n",
    "- [referer](https://en.wikipedia.org/wiki/HTTP_referer):  This is the address of the previous web page from which a link to the currently requested page was followed. \n",
    "- [user-agent]( https://en.wikipedia.org/wiki/User_agent#User_agent_identification): any software, acting on behalf of a user. It often identifies itself, its application type, operating system, device model, software vendor, or software revision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A code of 200 means success in the world of the web. View the HTTP response status codes here, including the famous 404: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=How+to+search+Google+using+Python\n"
     ]
    },
    {
     "data": {
      "text/plain": "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/SearchResultsPage\" lang=\"de\"><head><meta charset=\"UTF-8\"><meta content=\"origin\" name=\"referrer\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>How to search Google using Python - Google Suche</title><script nonce=\"xME6uIwMpS0Kv-RNTeqqbA\">(function(){var b=window.addEventListener;window.addEventListener=function(a,c,d){\"unload\"!==a&&b(a,c,d)};}).call(this);(function(){window.google={kEI:\\'Qdk1ZKDUFOuJ9u8P-bCI6Ac\\',kEXPI:\\'31\\',kBL:\\'x4dB\\',kOPI:89978449};google.sn=\\'web\\';google.kHL=\\'de\\';})();(function(){\\nvar e=this||self;var g,h=[];function k(a){for(var c;a&&(!a.getAttribute||!(c=a.getAttribute(\"eid\")));)a=a.parentNode;return c||g}function l(a){for(var c=null;a&&(!a.getAttribute||!(c=a.getAttribute(\"leid\")));)a=a.parentNode;return c}function m(a){/^http:/i.test(a)&&\"https:\"===window.location.protocol&&(google.ml&&google.ml(Error(\"a\"),!1,{src:a,glmm:1}),a=\"\");return a}\\nfunction p(a,c,b,f){var d=\"\";-1===c.search(\"&ei=\")&&(d=\"&ei=\"+k(b),-1===c.search(\"&lei=\")&&(b=l(b))&&(d+=\"&lei=\"+b));b=\"\";e._cshid&&-1===c.search(\"&cshid=\")&&\"slh\"!==a&&(b=\"&cshid=\"+e._cshid);return\"/\"+(f||\"gen_204\")+\"?atyp=i&ct=\"+String(a)+\"&cad=\"+(c+d)+\"&zx=\"+String(Date.now())+b};g=google.kEI;google.getEI=k;google.getLEI=l;google.ml=function(){return null};google.log=function(a,c,b,f,d){b||(b=p(a,c,f,d));if(b=m(b)){a=new Image;var n=h.length;h[n]=a;a.onerror=a.onload=a.onabort=function(){delete h[n]};a.src=b}};google.logUrl=function(a){return p(\"\",a)};}).call(this);(function(){google.y={};google.sy=[];google.x=function(a,b){if(a)var c=a.id;else{do c=Math.random();while(google.y[c])}google.y[c]=[a,b];return!1};google.sx=function(a){google.sy.push(a)};google.lm=[];google.plm=function(a){google.lm.push.apply(google.lm,a)};google.lq=[];google.load=function(a,b,c){google.lq.push([[a],b,c])};google.loadAll=function(a,b){google.lq.push([a,b])};google.bx=!1;google.lx=function(){};}).call(this);google.'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r.url)\n",
    "r.text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indeed get a result, but the result is just the HTML code for Google's webpage containing the results. It is possible to actually extract the search results from this mess (and various companies offer this as a paid service) but it requires further knowledge of web scraping and is not ideal as the format of these pages that Google gives you might change. These pages are designed for being visually rendered by a web browser and read by humans, not for being read by machines.\n",
    "\n",
    "Fortunately, Google also offers programmatic access to its search services through an API, to a limited extent, which avoids the above complications with headers and web scraping.\n",
    "\n",
    "## Working with APIs\n",
    "\n",
    "An **Application Programming Interface** is a set of protocols that defines how software programs communicate among eachother. Without APIs, we have to scrape the Web or get the data directly. With APIs, we often can get structured data: it is a much more convenient way to work.\n",
    "\n",
    "APIs are a great option in that they implement extensively tested routines (**high reliability**). However, you should spend time in learning how they work and, in some cases, they don't allow you to access the piece of information you may need (**low flexibility**).\n",
    "\n",
    "In this assignment, we will see how we can use Google's Custom Search API to build our own search engine on a specific topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. My First Search Engine\n",
    "\n",
    "In the first assignment, you'll:\n",
    "* Identify a specific topic of interest, the purpose of the vertical search engine, and the selection principles used to determine what's in and what's not in.\n",
    "* Build you very own vertical search engine using Google Co-op.\n",
    "* Evaluate the performance of your vertical search engine.\n",
    "\n",
    "## Subject, Purpose, and Selection Principles\n",
    "\n",
    "In any sort of data-driven research, you need to specify what kind of data is in and what kind of data is out. This is needed to clarify your domain of research and to make your research reproducible to others.\n",
    "\n",
    "First select a *subject* or topic for which you want to build a vertical search engine.  Generally speaking, a very specific topic like *Miffy (Nijntje)*, *Dodo's*, or *Olympic Games in  Amsterdam 1992* works better than general topics like *Literature*, *Ornithology*, or *Sports*.  \n",
    "\n",
    "Discuss the following issues, and write down your findings in the section below. You will have to specify the subject very specifically in terms of the *purpose* of the vertical search engine: what is the goal of the search engine (what should it make possible), and who are the envisaged users (what are special characteristics of the audience, in terms of background knowledge and preferences)?  You also have to translate this purpose into clear *selection principles*: what sites/pages do belong in the search engine, and---more importantly---what sites/pages do not belong in it. Give examples of sites that are in, and that are out, and explain this using your selection principles.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "In practice, spiral development works best. That is, after an initial formulation of the subject, immediately build an initial version of the vertical search engine, and let it evolve in parallel. So, feel free to return to this section later to improve it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Part 1: Description of my search engine\n",
    "\n",
    "I will be building a vertical search engine on the topic of **special pensions** and EU Funds in Romania. The purpose of this vertical search engine is to quantify the algorithmic influence of Google in presenting the results from various news websites as well as their political bias. The selection principles are the following:\n",
    "\n",
    "The search engine will only use the top 20 most acessed news websites in Romania. The selection of these websites is based on the data from Statista (https://www.statista.com/statistics/271695/top-20-most-visited-news-websites-in-romania/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Vertical Search Engine\n",
    "\n",
    "We will use Google Co-op's custom search engine http://cse.google.com/. Follow these steps to create your search engine:\n",
    "\n",
    "* Click on ''New Search Engine'' and sign in.\n",
    "* Specify a list of websites to search. You can start with a few websites, and add more later (aim for 10-20). If you add too many, it may not search all of them --- you can see this in the Control Panel. Only if a website has a green checkmark, it will be searched.\n",
    "* Enter the basic information: language, name.\n",
    "* Click on ''Create''.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Searching sites to include with Google first, and then search for them a little later will not result in a fair evaluation of the effectiveness of Google (due to personalization against your recent search history). In order to have a fair comparison, please use another search engine such as  \\url{https://onesearch.com/} or \\url{https://duckduckgo.com/} (both powered by non-personalized Bing API results) to discover sites to include.  Alternatively, you can develop with Google, but later compare your search engine to another large search engine.\n",
    "</div>\n",
    "\n",
    "You can now try your own search engine by clicking ''View it on the Web.''  Your own search engine now has\n",
    "its own homepage, and a  control panel to help further develop the search engine (i.e., add and manage the sites; search\n",
    "refinements; look-and-feel; collaboration; etc.). Please include a link to your search engine in the text box below `https://cse.google.com/cse/publicurl?cx='Search_engine_unique_ID'` e.g. https://cse.google.com/cse?cx=015090763398590173596:fny6ovbqr4y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report part 2: Search engine link and List of Websites\n",
    "\n",
    "#### Search engine link\n",
    "https://cse.google.com/cse?cx=26597891398fe4085#gsc.tab=0\n",
    "#### List of websites\n",
    "digi24.ro\n",
    "libertatea.ro\n",
    "adevarul.ro\n",
    "stirileprotv.ro\n",
    "hotnews.ro\n",
    "stiripesurse.ro\n",
    "stirileprotv.ro\n",
    "ziare.com\n",
    "evz.ro\n",
    "observatornews.ro\n",
    "g4media.ro\n",
    "dcnews.ro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access your search engine from Python\n",
    "\n",
    "To use your search engine in Python, you need two things: your Search Engine ID (visible in the CSE control panel) and an API key. To get a key, go to this page: https://developers.google.com/custom-search/v1/introduction and click Get a Key.\n",
    "\n",
    "Now, we can try to search using Python. Insert the two things you just obtained in the code block below and run it.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "In most real API access situations, you would not put your keys in the notebook like this for security reasons. Instead, you would put it in a separate file and load that file. But for now, we will do it like this for convenience.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Reading the API key and Search Engine ID from a JSON file\n",
    "with open('apistuff.json') as f:\n",
    "    data = json.load(f)\n",
    "    API_KEY = data[\"API_KEY\"]\n",
    "    SEARCH_ENGINE_ID = data[\"SEARCH_ENGINE_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The query you want to search for.\n",
    "query = \"Pensii Speciale PNRR\"\n",
    "\n",
    "# using the first page\n",
    "page = 1\n",
    "\n",
    "# Making the link to Google to search\n",
    "# Documentation on this topic: https://developers.google.com/custom-search/v1/using_rest\n",
    "# Start should be the index of the first result you want to see, and each page has 10 results.\n",
    "# So if we want to see page 2, we need to start at result number 11.\n",
    "start = (page - 1) * 10 + 1\n",
    "# Building the link to send to Google\n",
    "url = f\"https://www.googleapis.com/customsearch/v1?key={API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}&start={start}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Warning: With the free version, you can only make 100 queries per day to Google (the requests.get part). So don't run the \"get\" queries too often or you will hit the limit before being able to finish the assignment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the search request to the API. This is a cell you want to run as few times as possible.\n",
    "data = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = data.get(\"items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a dictionary *data* containing the result of our request. The actual search results are stored in `data[\"items\"]` so we have saved that to the variable search_results. We can re-use this variable to avoid making many requests to Google.\n",
    "\n",
    "### Read through the search results\n",
    "\n",
    "Let's print the results in a nice way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Result #1 ===============\n",
      "Title: Ministrul responsabil cu PNRR sugerează că România ar putea ...\n",
      "Description: Mar 22, 2023 ... Ne pregatim sa spunem adio PNRR-ului, pensiile speciale erau doar ... Suntem condusi de nemernicii care au sau vor avea pensii speciale si ...\n",
      "URL: www.hotnews.ro \n",
      "\n",
      "=============== Result #2 ===============\n",
      "Title: EXCLUSIV Reforma pensiilor speciale: Comisia Europeană cere ...\n",
      "Description: Mar 21, 2023 ... Reamintim că România și-a asumat prin PNRR reformarea pensiilor speciale ... Tags: pensii magistrați, pensii militare, pensii speciale, PNRR.\n",
      "URL: www.g4media.ro \n",
      "\n",
      "=============== Result #3 ===============\n",
      "Title: Ciolacu, despre pensiile speciale: Dacă luăm ad literam ce ne-am ...\n",
      "Description: Mar 22, 2023 ... ... literam” măsurile de reformă a pensiilor speciale asumate în PNRR, ... pensiilor speciale și că „nu poți să ieși la pensie la 45 de ani, ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #4 ===============\n",
      "Title: Surse - Avertismentul Comisiei Europene: Modificați legea ...\n",
      "Description: Apr 5, 2023 ... ... pensiilor speciale nu se negociază, ci se face ca la carte sau ca în PNRR. ... cu beneficiarii de pensii speciale rămân nesemnificative.\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #5 ===============\n",
      "Title: Noi precizări ale Comisiei Europene legate de pensiile speciale. Ce ...\n",
      "Description: Feb 15, 2023 ... Ce trebuie să facă România pentru a primi miliardele din PNRR. HotNews.ro ... Vezi cu ca afară tot pensii speciale se cheamă.\n",
      "URL: www.hotnews.ro \n",
      "\n",
      "=============== Result #6 ===============\n",
      "Title: Bode, despre încadrarea pensiilor militare ca pensii speciale: M-am ...\n",
      "Description: Jul 14, 2022 ... Ministrul de Interne, Lucian Bode, a declarat, joi, că a „citit de mai multe ori articolul 215 din PNRR” privind încadrarea pensiilor ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #7 ===============\n",
      "Title: Marcel Boloș, la Interviurile Digi24.ro: Reforma asumată în PNRR ...\n",
      "Description: Mar 23, 2023 ... Comisia monitorizează sustenabilitatea pe care o avem pentru pensiile speciale și pentru pensii în general, adică cât ne ajung banii ca pe ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #8 ===============\n",
      "Title: Boloş: Jalonul din PNRR privind pensiile speciale are termen limită ...\n",
      "Description: Jul 13, 2022 ... „În toate statele membre ale Uniunii Europene pentru aceste grupe de funcţionari şi personal încadrat există pensii de serviciu. Deci, nu cred ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #9 ===============\n",
      "Title: BREAKING Ministerul Justiției introduce noi categorii de grefieri ...\n",
      "Description: Feb 22, 2023 ... ... introduce noi categorii de grefieri care primesc pensii speciale, în pline negocieri pentru reformarea pensiilor speciale în cadrul PNRR ...\n",
      "URL: www.g4media.ro \n",
      "\n",
      "=============== Result #10 ===============\n",
      "Title: PSD: România nu își permite să rateze fondurile europene din ...\n",
      "Description: Feb 28, 2023 ... PSD mai precizează că miniștrii care gestionează pensii speciale vor ... să rateze fondurile europene din PNRR din cauza pensiilor speciale.\n",
      "URL: www.g4media.ro \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_search_results(search_results):\n",
    "    for i, search_item in enumerate(search_results, start=1):\n",
    "        # get the page title\n",
    "        title = search_item.get(\"title\")\n",
    "        # page snippet\n",
    "        snippet = search_item.get(\"snippet\")\n",
    "        # alternatively, you can get the HTML snippet (bolded keywords)\n",
    "        html_snippet = search_item.get(\"htmlSnippet\")\n",
    "        # extract the page url and reduce it to the main domain\n",
    "        link = search_item.get(\"link\")\n",
    "        link = link.split(\"/\")[2]\n",
    "        # print the results\n",
    "        print(\"=\"*15, f\"Result #{i+start-1}\", \"=\"*15)\n",
    "        print(\"Title:\", title)\n",
    "        print(\"Description:\", snippet)\n",
    "        print(\"URL:\", link, \"\\n\")\n",
    "        \n",
    "print_search_results(search_results) #Print the search results we just got using the function we just defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: Can You Beat Google?\n",
    "\n",
    "Once you are completely satisfied with your vertical search engine, we\n",
    "move to the final stage: evaluate the effectiveness of your vertical\n",
    "search engine in comparison to a general-purpose search engine.  Please\n",
    "document the evaluations below.\n",
    "\n",
    "* Search/navigate/browse to a web page that is part of your\n",
    "  collection (List of Websites).  Skim-read the page and close the page in your\n",
    "  browser. Now write down 2-3 keywords below that you may use when trying to\n",
    "  find this page again at a later time.  Do this for **5 pages**\n",
    "  in total. This will be our evaluation dataset: we say that a search engine is good if it finds those pages using those keywords. Write the keywords and link for each of the 5 pages in the Python dictionary below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define a dictionary with our 5 webpages and keywords\n",
    "eval_dataset_dict = {\n",
    "    \"PNRR\": \"www.digi24.ro\",\n",
    "    \"europene\": \"media.hotnews.ro\",\n",
    "    \"fonduri\": \"stirileprotv.ro\",\n",
    "    \"UE\": \"www.g4media.ro\",\n",
    "    \"pensii speciale\" : \"www.digi24.ro\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the Google results for each keyword query we defined above using your vertical search engine. We want to do this only once to avoid hitting the 100 limit, so **avoid running this code block multiple times**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_dict = {} #new dictionary to store query results\n",
    "\n",
    "for query in eval_dataset_dict:\n",
    "    #loop through each of the 5 search queries and search for them using our vertical search engine\n",
    "    \n",
    "    #Make use of the API key and search engine ID you defined above\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?key={API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}&start={1}\"\n",
    "    data = requests.get(url).json() #Ask Google for the results\n",
    "    eval_results_dict[query] = data.get(\"items\") #Extract the found items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have an additional dictionary *eval_results_dict* that contains our 5 keyword queries and the results from our search engine. We can re-use this variable to avoid making many requests to Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write an evaluation function.\n",
    "\n",
    "* Write a re-usable function that takes as its input a query from this dictionary and the results of your search engine for that query (as stored in *eval_results_dict*). The function should find the rank (result number, 1, 2, 3 ...) at which the page appears in the top 10 in your results. Then, it should calculate $\\frac{1}{rank}$ as the score for this search (so if its at rank 1, you get a score of $\\frac{1}{1} = 1$, rank 2 gives  $\\frac{1}{2}$, etc.  If its below rank 10, just score 0. Return the score. For more details on this evaluation: see http://en.wikipedia.org/wiki/Mean_reciprocal_rank \n",
    "\n",
    "Feel free to make use of the *print_search_results()* function I defined above, or adapt it. I provide a start for the code below. Feel free to also expand it by e.g. computing the mean of all the scores. Or if you are confident, delete my code and do it from scratch yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing a function to evaluate the results of our search engine\n",
    "def evaluate_result(search_results, target_link):\n",
    "    #Loop through the search results and find the rank of the target link\n",
    "    for i, search_item in enumerate(search_results, start=1):\n",
    "        # get the page title\n",
    "        title = search_item.get(\"title\")\n",
    "        # page snippet\n",
    "        snippet = search_item.get(\"snippet\")\n",
    "        # alternatively, you can get the HTML snippet (bolded keywords)\n",
    "        html_snippet = search_item.get(\"htmlSnippet\")\n",
    "        # extract the page url and reduce it to the main domain\n",
    "        link = search_item.get(\"link\")\n",
    "        link = link.split(\"/\")[2]\n",
    "        # print the results\n",
    "        print(\"=\"*15, f\"Result #{i}\", \"=\"*15)\n",
    "        print(\"Title:\", title)\n",
    "        print(\"Description:\", snippet)\n",
    "        print(\"URL:\", link, \"\\n\")\n",
    "        #Check if this is the target link\n",
    "        if link == target_link:\n",
    "            #If that's the case, return the RRS\n",
    "            return 1/i\n",
    "\n",
    "    #If we get here, it means it didn't find the target link in the top 10 results\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to evaluate all queries in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Result #1 ===============\n",
      "Title: PNRR | Digi24\n",
      "Description: PNRR: avem 451 stiri despre PNRR. Citeste acum toate articole despre PNRR pe Digi24.ro.\n",
      "URL: www.digi24.ro \n",
      "\n",
      "Score for query 'PNRR': 1.0\n",
      "=============== Result #1 ===============\n",
      "Title: Curtea de Justiție a Uniunii Europene COMUNICAT DE PRESĂ nr ...\n",
      "Description: Curtea de Justiție a Uniunii Europene. COMUNICAT DE PRESĂ nr. 54/14. Luxemburg, 8 aprilie 2014. Hotărârea în cauzele conexate C-293/12 și C-594/12.\n",
      "URL: media.hotnews.ro \n",
      "\n",
      "Score for query 'europene': 1.0\n",
      "=============== Result #1 ===============\n",
      "Title: Fonduri europene, succese românești - Stirileprotv.ro\n",
      "Description: O serie de reportaje despre proiecte de succes realizate cu fonduri europene. Vorbim despre afaceri construite de la zero, comunități în creștere, ...\n",
      "URL: stirileprotv.ro \n",
      "\n",
      "Score for query 'fonduri': 1.0\n",
      "=============== Result #1 ===============\n",
      "Title: Siegfried Mureșan: Georgia riscă să piardă sprijinul UE. Deja a ...\n",
      "Description: Mar 8, 2023 ... Tocmai de aceea, anul trecut, UE a oferit Republicii Moldova și Ucrainei ... de state candidate pentru aderarea la UE și nu i-a oferit acest.\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #2 ===============\n",
      "Title: Aurescu despre discursul anti-UE al lui Viktor Orban: „Este regretabil ...\n",
      "Description: Jul 25, 2022 ... În acest weekend am urmărit cu toții declarațiile anti-UE și pro-ruse făcute de către Prim-ministrul Ungariei, Viktor Orban, în contextul ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #3 ===============\n",
      "Title: Dragnea: NATO și UE au finanțat statul paralel | Digi24\n",
      "Description: Dragnea: NATO și UE au finanțat statul paralel. Data publicării: 11.06.2018 01:02. steag ue uniunea europeana nato shutterstock_1046673724.\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #4 ===============\n",
      "Title: Ce prevede Articolul 7 din Tratatul UE, „arma nucleară” împotriva ...\n",
      "Description: Sep 12, 2018 ... Parlamentul European a aprobat, miercuri, o rezoluție prin care se demarează procedura pentru declanșarea Articolului 7 al Tratatului UE ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #5 ===============\n",
      "Title: Efectul Brexit: Scoţia speră „să se alăture UE” ca naţiune ...\n",
      "Description: Jan 2, 2021 ... Editor : M.L.. Etichete: scotia independenta · nicola sturgeon · brexit · scotia ue. Urmărește știrile Digi24.ro și pe Google News.\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #6 ===============\n",
      "Title: Georgia a semnat cererea de aderare la Uniunea Europeană ...\n",
      "Description: Mar 3, 2022 ... Drapel al UE în fața sediului Comisiei Europene. Foto: Getty Images. Din articol. Și Moldova va aplica pentru aderarea la UE.\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #7 ===============\n",
      "Title: TikTok ar putea fi interzis în UE dacă nu respectă legislaţia ...\n",
      "Description: Jan 20, 2023 ... TikTok ar putea fi interzis în UE dacă nu respectă legislaţia comunitară, avertizează un comisar european ... Aplicatţia TikTok văzută pe ecranul ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #8 ===============\n",
      "Title: Regulamentul (UE) nr. 994/2010 al Parlamentului European și al ...\n",
      "Description: Nov 12, 2010 ... un plan de acțiune al UE pentru securitate și solida ritate în domeniul energiei”, ca, de exemplu, coridorul sudic al gazelor (Nabucco și ...\n",
      "URL: media.hotnews.ro \n",
      "\n",
      "=============== Result #9 ===============\n",
      "Title: Erdogan, către UE: Arătaţi Turciei aceeaşi sensibilitate pe care o ...\n",
      "Description: Mar 1, 2022 ... Președintele Turciei, Recep Erdogan, a cerut Uniunii Europene să trateze Turcia la fel cum tratează Ucraina, în ce privește aspirațiile de ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "=============== Result #10 ===============\n",
      "Title: Eurostat: Bulgaria, Letonia și România sunt țările din UE cu cel ...\n",
      "Description: Jan 28, 2022 ... Astfel, 13 state membre din estul şi sudul UE aveau la începutul acestui an salarii minime sub 1.000 de euro pe lună: Bulgaria (332 euro), ...\n",
      "URL: www.digi24.ro \n",
      "\n",
      "Score for query 'UE': 0\n",
      "=============== Result #1 ===============\n",
      "Title: pensii speciale | Digi24\n",
      "Description: pensii speciale: avem 384 stiri despre pensii speciale. Citeste acum toate articole despre pensii speciale pe Digi24.ro.\n",
      "URL: www.digi24.ro \n",
      "\n",
      "Score for query 'pensii speciale': 1.0\n",
      "Mean score: 0.8\n"
     ]
    }
   ],
   "source": [
    "#Intialize a list to store the scores\n",
    "scores = []\n",
    "#Iterate through the queries in our dataset and add the scores to our list\n",
    "for query in eval_dataset_dict:\n",
    "    #Get the target link for this query\n",
    "    target_link = eval_dataset_dict[query]\n",
    "    #Get the search results for this query\n",
    "    search_results = eval_results_dict[query]\n",
    "    #Evaluate the results\n",
    "    score = evaluate_result(search_results, target_link)\n",
    "    #Add the score to our list\n",
    "    scores.append(score)\n",
    "    print(f\"Score for query '{query}': {score}\")\n",
    "#Compute the mean score\n",
    "mean_score = sum(scores)/len(scores)\n",
    "print(f\"Mean score: {mean_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Debugging advice: If you are struggling to understand what is inside the variables, print them!\n",
    "</div>\n",
    "\n",
    "* Do the same using the general search engine, www.google.com - here you can just search for your keywords and compute the RR scores by hand. \n",
    "* Now compare the average score for both search engines, and also look at the number of topics where one or the other is better.\n",
    "* Is your vertical search engine better than Google?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report part 3: Evaluation\n",
    "#### Because the results are Romanian, and in order to give the algorithm a fair chance I will use a VPN to Romania.\n",
    " Comparing the first keyword (e.g \"PNRR\": \"www.digi24.ro\") with Google, the vertical search engine does way better. It finds the correct result in the first position while Google first displays information from the EU websites, thus, getting a 0\n",
    "\n",
    "The second keyword (e.g \"europene\": \"media.hotnews.ro\") is also found in the first position by the vertical search engine, whiile Google, displays the EU website again for the first few pages of results, thus getting a 0 again.\n",
    "\n",
    "The third keyword (e.g \"UE\": \"www.g4media.ro\") is found in the first position by the vertical search engine, while Google displays other websites for the first few pages of results, thus getting a 0 again.\n",
    "\n",
    "The fourth keyword (e.g \"UE\": \"www.g4media.ro\") is not a great result for the vertical search engine, but, again, Google fails to display what I am interested in, thus getting a 0 again.\n",
    "\n",
    "The fifth keyword (e.g. \"pensii speciale\" : \"www.digi24.ro\") is found in the first position by the vertical search engine, but Google also displays the correct result in the first position, thus getting a 1.\n",
    "\n",
    "#### The average score for the VSE is 0.8 while Google gets a 0.2, thus, the VSE is better than Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "Feel free to do some further exploration here to go for the bonus points. For example, you could evaluate your search engine's Precision (http://en.wikipedia.org/wiki/Precision_(information_retrieval)#Precision). For this, you think up a general topic, and count how many of the results pertain to that topic, and again compare it to Google.\n",
    "\n",
    "You could also reflect on the strengths and limitations of text-based searching. Viewing documents as just ''bags of words'' works sometimes surprisingly well, but also has significant limitations.  Was the search engine perfect (finding exactly all, and only, relevant information), and why not?  What do you think are strengths and weaknesses of standard keyword search?  What is the main barrier when it fails to retrieve a relevant document (is it on the user's end in the query formulation, is it on the system's end in the ranking component, or is in the document's end in the way information is expressed?)   In what situations are the limitations harmful?  Is there a way to compensate for these?   For which kinds of tasks would this imperfect tool already be very useful?    What would be different if advanced computational language understanding was possible? Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report part 4: Discussion/Reflection\n",
    "\n",
    "Overall, the VSE is better than Google, but, it is not perfect. It does not find the correct result for the fourth keyword, but, it does find the correct result for the other four keywords. This is to be expected, as most of the keywords are not precise enough to indicate to Google that I request news, but rather, it is a general search for the EU and EU related topics.\n",
    "\n",
    "This shows clearly that having a VSE is great for very specific topics and it can help you get to the results you desire much faster.\n",
    "\n",
    "Overall, this assignment helped me understand why CSEs are essential for specific topics and why they are so useful. I also learned how to use the Google API and how to use it to get the results I want. I also learned how to evaluate the results and how to compare them to other search engines.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_CollaborativeAssignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
