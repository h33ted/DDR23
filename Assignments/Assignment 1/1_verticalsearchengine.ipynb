{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV-UrkvK3HBQ"
   },
   "source": [
    "# Data-Driven Research Assignment 1: Build your own Vertical Search Engine\n",
    "This notebook contains the first individual graded assignment of the 2023 Data-Driven Research course. In this assignment you will build your own search engine -- and compare against search engine giant Google -- with a realistic chance to do better than Google! \n",
    "\n",
    "To complete the assignment, fill in the **Report part 1**, **Report part 2** and **Report part 3** and **Report part 4**, and complete the **code** in the last section that is needed to write Report part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13WY-Pd4m1Nq"
   },
   "source": [
    "This is an individual assignment. In the text cell below, please add your name.\n",
    "\n",
    "If you used code or a solution from the internet (such as StackOverflow) or another external resource, please make reference to it (in any format). Unattributed copied code will be considered plagiarism and therefore fraud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author of this answer: George Christian Cotea - 13842013**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV4eOyrVqRHQ"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Search engines provide a crucial role in making sense of the almost infinite amount of information online. In fact your mental model of what the web is, is completely determined by the small fraction of web data served in a streamlined way by search engines.  You reliance on search engines also makes them the gatekeeper of information: with millions or billions of search results for every query they determine the ranking with only the first handful of them gets any clicks.   Is this generic approach really optimal for everyone and any topic?\n",
    "\n",
    "A *Vertical Search Engine* is a \"specialized\" search engine that focuses on a specific domain or service, tailored to the\n",
    "particular information needs of niche audiences and professions.  Search experts believe that the performance of general-purpose search engines (such as http://google.com/, http://bing.com/, and http://onesearch.com/ or regional champions like https://baidu.cn/ and https://yandex.ru/) cannot improve much due to the short and highly ambiguous queries that are standard on the web.  A natural alternative to the one-size-fits-all approach of general-purpose search engines is the\n",
    "use of a dedicated vertical search engine, which is expected to provide more focused search results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Accessing Google using Python\n",
    "\n",
    "Probably, you normally access the web by searching for something through a search engine like Google. But what if you want to make use of this information for data-driven or quantitative research purposes? It's kind of a hassle to copy-paste all your search results into a file for further analysis. \n",
    "\n",
    "We could use Python's Request library to simply request a page of search results from Google. Let's try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # External package: https://requests.readthedocs.io/en/master/\n",
    "\n",
    "# Example of a Google search\n",
    "query = \"How to search Google using Python\"\n",
    "headers = {\n",
    "    \"referer\":\"referer: https://www.google.com/\",\n",
    "    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "with requests.Session() as s:\n",
    "    s.post('https://www.google.com/search', params={'q': query}, headers=headers)\n",
    "    r = s.get('https://www.google.com/search', params={'q': query}, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are wondering what the \"headers\" is, it provides information about the user (mainly your browser) to the website. We have to add them here for Google to view us as a regular user and not a first-time user, to avoid getting cookies and privacy consent popups instead of the results that we want.\n",
    "\n",
    "You can find a selection of HTTP headers [here](https://en.wikipedia.org/wiki/List_of_HTTP_header_fields). Here's an explanation for the ones used above:\n",
    "- [referer](https://en.wikipedia.org/wiki/HTTP_referer):  This is the address of the previous web page from which a link to the currently requested page was followed. \n",
    "- [user-agent]( https://en.wikipedia.org/wiki/User_agent#User_agent_identification): any software, acting on behalf of a user. It often identifies itself, its application type, operating system, device model, software vendor, or software revision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A code of 200 means success in the world of the web. View the HTTP response status codes here, including the famous 404: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=How+to+search+Google+using+Python\n"
     ]
    },
    {
     "data": {
      "text/plain": "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/SearchResultsPage\" lang=\"de\"><head><meta charset=\"UTF-8\"><meta content=\"origin\" name=\"referrer\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>How to search Google using Python - Google Suche</title><script nonce=\"xME6uIwMpS0Kv-RNTeqqbA\">(function(){var b=window.addEventListener;window.addEventListener=function(a,c,d){\"unload\"!==a&&b(a,c,d)};}).call(this);(function(){window.google={kEI:\\'Qdk1ZKDUFOuJ9u8P-bCI6Ac\\',kEXPI:\\'31\\',kBL:\\'x4dB\\',kOPI:89978449};google.sn=\\'web\\';google.kHL=\\'de\\';})();(function(){\\nvar e=this||self;var g,h=[];function k(a){for(var c;a&&(!a.getAttribute||!(c=a.getAttribute(\"eid\")));)a=a.parentNode;return c||g}function l(a){for(var c=null;a&&(!a.getAttribute||!(c=a.getAttribute(\"leid\")));)a=a.parentNode;return c}function m(a){/^http:/i.test(a)&&\"https:\"===window.location.protocol&&(google.ml&&google.ml(Error(\"a\"),!1,{src:a,glmm:1}),a=\"\");return a}\\nfunction p(a,c,b,f){var d=\"\";-1===c.search(\"&ei=\")&&(d=\"&ei=\"+k(b),-1===c.search(\"&lei=\")&&(b=l(b))&&(d+=\"&lei=\"+b));b=\"\";e._cshid&&-1===c.search(\"&cshid=\")&&\"slh\"!==a&&(b=\"&cshid=\"+e._cshid);return\"/\"+(f||\"gen_204\")+\"?atyp=i&ct=\"+String(a)+\"&cad=\"+(c+d)+\"&zx=\"+String(Date.now())+b};g=google.kEI;google.getEI=k;google.getLEI=l;google.ml=function(){return null};google.log=function(a,c,b,f,d){b||(b=p(a,c,f,d));if(b=m(b)){a=new Image;var n=h.length;h[n]=a;a.onerror=a.onload=a.onabort=function(){delete h[n]};a.src=b}};google.logUrl=function(a){return p(\"\",a)};}).call(this);(function(){google.y={};google.sy=[];google.x=function(a,b){if(a)var c=a.id;else{do c=Math.random();while(google.y[c])}google.y[c]=[a,b];return!1};google.sx=function(a){google.sy.push(a)};google.lm=[];google.plm=function(a){google.lm.push.apply(google.lm,a)};google.lq=[];google.load=function(a,b,c){google.lq.push([[a],b,c])};google.loadAll=function(a,b){google.lq.push([a,b])};google.bx=!1;google.lx=function(){};}).call(this);google.'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r.url)\n",
    "r.text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indeed get a result, but the result is just the HTML code for Google's webpage containing the results. It is possible to actually extract the search results from this mess (and various companies offer this as a paid service) but it requires further knowledge of web scraping and is not ideal as the format of these pages that Google gives you might change. These pages are designed for being visually rendered by a web browser and read by humans, not for being read by machines.\n",
    "\n",
    "Fortunately, Google also offers programmatic access to its search services through an API, to a limited extent, which avoids the above complications with headers and web scraping.\n",
    "\n",
    "## Working with APIs\n",
    "\n",
    "An **Application Programming Interface** is a set of protocols that defines how software programs communicate among eachother. Without APIs, we have to scrape the Web or get the data directly. With APIs, we often can get structured data: it is a much more convenient way to work.\n",
    "\n",
    "APIs are a great option in that they implement extensively tested routines (**high reliability**). However, you should spend time in learning how they work and, in some cases, they don't allow you to access the piece of information you may need (**low flexibility**).\n",
    "\n",
    "In this assignment, we will see how we can use Google's Custom Search API to build our own search engine on a specific topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. My First Search Engine\n",
    "\n",
    "In the first assignment, you'll:\n",
    "* Identify a specific topic of interest, the purpose of the vertical search engine, and the selection principles used to determine what's in and what's not in.\n",
    "* Build you very own vertical search engine using Google Co-op.\n",
    "* Evaluate the performance of your vertical search engine.\n",
    "\n",
    "## Subject, Purpose, and Selection Principles\n",
    "\n",
    "In any sort of data-driven research, you need to specify what kind of data is in and what kind of data is out. This is needed to clarify your domain of research and to make your research reproducible to others.\n",
    "\n",
    "First select a *subject* or topic for which you want to build a vertical search engine.  Generally speaking, a very specific topic like *Miffy (Nijntje)*, *Dodo's*, or *Olympic Games in  Amsterdam 1992* works better than general topics like *Literature*, *Ornithology*, or *Sports*.  \n",
    "\n",
    "Discuss the following issues, and write down your findings in the section below. You will have to specify the subject very specifically in terms of the *purpose* of the vertical search engine: what is the goal of the search engine (what should it make possible), and who are the envisaged users (what are special characteristics of the audience, in terms of background knowledge and preferences)?  You also have to translate this purpose into clear *selection principles*: what sites/pages do belong in the search engine, and---more importantly---what sites/pages do not belong in it. Give examples of sites that are in, and that are out, and explain this using your selection principles.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "In practice, spiral development works best. That is, after an initial formulation of the subject, immediately build an initial version of the vertical search engine, and let it evolve in parallel. So, feel free to return to this section later to improve it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Part 1: Description of my search engine\n",
    "\n",
    "(your discussion here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Vertical Search Engine\n",
    "\n",
    "We will use Google Co-op's custom search engine http://cse.google.com/. Follow these steps to create your search engine:\n",
    "\n",
    "* Click on ''New Search Engine'' and sign in.\n",
    "* Specify a list of websites to search. You can start with a few websites, and add more later (aim for 10-20). If you add too many, it may not search all of them --- you can see this in the Control Panel. Only if a website has a green checkmark, it will be searched.\n",
    "* Enter the basic information: language, name.\n",
    "* Click on ''Create''.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Searching sites to include with Google first, and then search for them a little later will not result in a fair evaluation of the effectiveness of Google (due to personalization against your recent search history). In order to have a fair comparison, please use another search engine such as  \\url{https://onesearch.com/} or \\url{https://duckduckgo.com/} (both powered by non-personalized Bing API results) to discover sites to include.  Alternatively, you can develop with Google, but later compare your search engine to another large search engine.\n",
    "</div>\n",
    "\n",
    "You can now try your own search engine by clicking ''View it on the Web.''  Your own search engine now has\n",
    "its own homepage, and a  control panel to help further develop the search engine (i.e., add and manage the sites; search\n",
    "refinements; look-and-feel; collaboration; etc.). Please include a link to your search engine in the text box below `https://cse.google.com/cse/publicurl?cx='Search_engine_unique_ID'` e.g. https://cse.google.com/cse?cx=015090763398590173596:fny6ovbqr4y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report part 2: Search engine link and List of Websites\n",
    "\n",
    "(your search engine link and list of websites here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access your search engine from Python\n",
    "\n",
    "To use your search engine in Python, you need two things: your Search Engine ID (visible in the CSE control panel) and an API key. To get a key, go to this page: https://developers.google.com/custom-search/v1/introduction and click Get a Key.\n",
    "\n",
    "Now, we can try to search using Python. Insert the two things you just obtained in the code block below and run it.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "In most real API access situations, you would not put your keys in the notebook like this for security reasons. Instead, you would put it in a separate file and load that file. But for now, we will do it like this for convenience.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# get the API KEY here: https://developers.google.com/custom-search/v1/overview\n",
    "API_KEY = \"<INSERT_YOUR_API_KEY_HERE>\"\n",
    "# get your Search Engine ID on your CSE control panel\n",
    "SEARCH_ENGINE_ID = \"<INSERT_YOUR_SEARCH_ENGINE_ID_HERE>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The query you want to search for.\n",
    "query = \"test\"\n",
    "\n",
    "# using the first page\n",
    "page = 1\n",
    "\n",
    "# Making the link to Google to search\n",
    "# Documentation on this topic: https://developers.google.com/custom-search/v1/using_rest\n",
    "# Start should be the index of the first result you want to see, and each page has 10 results.\n",
    "# So if we want to see page 2, we need to start at result number 11.\n",
    "start = (page - 1) * 10 + 1\n",
    "# Building the link to send to Google\n",
    "url = f\"https://www.googleapis.com/customsearch/v1?key={API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}&start={start}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Warning: With the free version, you can only make 100 queries per day to Google (the requests.get part). So don't run the \"get\" queries too often or you will hit the limit before being able to finish the assignment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the search request to the API. This is a cell you want to run as few times as possible.\n",
    "data = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = data.get(\"items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a dictionary *data* containing the result of our request. The actual search results are stored in `data[\"items\"]` so we have saved that to the variable search_results. We can re-use this variable to avoid making many requests to Google.\n",
    "\n",
    "### Read through the search results\n",
    "\n",
    "Let's print the results in a nice way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_search_results(search_results):\n",
    "    for i, search_item in enumerate(search_results, start=1):\n",
    "        # get the page title\n",
    "        title = search_item.get(\"title\")\n",
    "        # page snippet\n",
    "        snippet = search_item.get(\"snippet\")\n",
    "        # alternatively, you can get the HTML snippet (bolded keywords)\n",
    "        html_snippet = search_item.get(\"htmlSnippet\")\n",
    "        # extract the page url\n",
    "        link = search_item.get(\"link\")\n",
    "        # print the results\n",
    "        print(\"=\"*15, f\"Result #{i+start-1}\", \"=\"*15)\n",
    "        print(\"Title:\", title)\n",
    "        print(\"Description:\", snippet)\n",
    "        print(\"URL:\", link, \"\\n\")\n",
    "        \n",
    "print_search_results(search_results) #Print the search results we just got using the function we just defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: Can You Beat Google?\n",
    "\n",
    "Once you are completely satisfied with your vertical search engine, we\n",
    "move to the final stage: evaluate the effectiveness of your vertical\n",
    "search engine in comparison to a general-purpose search engine.  Please\n",
    "document the evaluations below.\n",
    "\n",
    "* Search/navigate/browse to a web page that is part of your\n",
    "  collection (List of Websites).  Skim-read the page and close the page in your\n",
    "  browser. Now write down 2-3 keywords below that you may use when trying to\n",
    "  find this page again at a later time.  Do this for **5 pages**\n",
    "  in total. This will be our evaluation dataset: we say that a search engine is good if it finds those pages using those keywords. Write the keywords and link for each of the 5 pages in the Python dictionary below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define a dictionary with our 5 webpages and keywords\n",
    "eval_dataset_dict = {\n",
    "    \"keyword1 keyword2 keyword3\": \"https://example.com/\",\n",
    "    \"keyword3 keyword4\": \"https://wikipedia.com/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the Google results for each keyword query we defined above using your vertical search engine. We want to do this only once to avoid hitting the 100 limit, so **avoid running this code block multiple times**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_dict = {} #new dictionary to store query results\n",
    "\n",
    "for query in eval_dataset_dict:\n",
    "    #loop through each of the 5 search queries and search for them using our vertical search engine\n",
    "    \n",
    "    #Make use of the API key and search engine ID you defined above\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?key={API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}&start={1}\"\n",
    "    data = requests.get(url).json() #Ask Google for the results\n",
    "    eval_results_dict[query] = data.get(\"items\") #Extract the found items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have an additional dictionary *eval_results_dict* that contains our 5 keyword queries and the results from our search engine. We can re-use this variable to avoid making many requests to Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write an evaluation function.\n",
    "\n",
    "* Write a re-usable function that takes as its input a query from this dictionary and the results of your search engine for that query (as stored in *eval_results_dict*). The function should find the rank (result number, 1, 2, 3 ...) at which the page appears in the top 10 in your results. Then, it should calculate $\\frac{1}{rank}$ as the score for this search (so if its at rank 1, you get a score of $\\frac{1}{1} = 1$, rank 2 gives  $\\frac{1}{2}$, etc.  If its below rank 10, just score 0. Return the score. For more details on this evaluation: see http://en.wikipedia.org/wiki/Mean_reciprocal_rank \n",
    "\n",
    "Feel free to make use of the *print_search_results()* function I defined above, or adapt it. I provide a start for the code below. Feel free to also expand it by e.g. computing the mean of all the scores. Or if you are confident, delete my code and do it from scratch yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_result(search_results, target_link):\n",
    "    # A function that checks whether the target link was found\n",
    "    # in your search engine results, and returns the Reciprocal Rank.\n",
    "    \n",
    "    #Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to evaluate all queries in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in eval_results_dict: \n",
    "#Loop through all 5 search results obtained above\n",
    "    \n",
    "    search_results = eval_results_dict[query] #This contains the results given by your search engine\n",
    "    target_link = eval_dataset_dict[query] #This contains the link to the webpage it was supposed to find\n",
    "    \n",
    "    #Use your function to return the Reciprocal Rank score for this query\n",
    "    rr_score = evaluate_result(search_results, target_link)\n",
    "    \n",
    "    # Print the score for the link. I'm sure you can make the printing nicer.\n",
    "    print(f'For the page {target_link}, my search engine scored {rr_score}.')\n",
    "    \n",
    "# Try to also compute the average RR score for all the queries here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Debugging advice: If you are struggling to understand what is inside the variables, print them!\n",
    "</div>\n",
    "\n",
    "* Do the same using the general search engine, www.google.com - here you can just search for your keywords and compute the RR scores by hand. \n",
    "* Now compare the average score for both search engines, and also look at the number of topics where one or the other is better.\n",
    "* Is your vertical search engine better than Google?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report part 3: Evaluation\n",
    "\n",
    "(Put the comparison of your search engine with Google here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "Feel free to do some further exploration here to go for the bonus points. For example, you could evaluate your search engine's Precision (http://en.wikipedia.org/wiki/Precision_(information_retrieval)#Precision). For this, you think up a general topic, and count how many of the results pertain to that topic, and again compare it to Google.\n",
    "\n",
    "You could also reflect on the strengths and limitations of text-based searching. Viewing documents as just ''bags of words'' works sometimes surprisingly well, but also has significant limitations.  Was the search engine perfect (finding exactly all, and only, relevant information), and why not?  What do you think are strengths and weaknesses of standard keyword search?  What is the main barrier when it fails to retrieve a relevant document (is it on the user's end in the query formulation, is it on the system's end in the ranking component, or is in the document's end in the way information is expressed?)   In what situations are the limitations harmful?  Is there a way to compensate for these?   For which kinds of tasks would this imperfect tool already be very useful?    What would be different if advanced computational language understanding was possible?   Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report part 4: Discussion/Reflection\n",
    "\n",
    "(Discuss whether your vertical search engine is better than Google based on your evaluation results)\n",
    "\n",
    "(Further evaluation and/or reflection)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_CollaborativeAssignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
